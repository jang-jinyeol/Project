{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18-classifier.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jang-jinyeol/Project/blob/master/Resnet18_classifier_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlFwUFJFk1K1"
      },
      "source": [
        "# Mount to your google drive\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plJREy9SlMx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ef30ca4-0b7c-4f68-92b0-007bf9372b88"
      },
      "source": [
        "! ls 'drive/My Drive/Rosa_classifier'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data.npy\tval_data.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpI1I5_vl9P6"
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngWoj2OBa1iS"
      },
      "source": [
        "train_data = np.load('drive/My Drive/Rosa_classifier/train_data.npy', allow_pickle=True)\n",
        "val_data = np.load('drive/My Drive/Rosa_classifier/val_data.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhh_XuewrNHR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "bdded758-2b4a-4c74-ae74-988be3e3e163"
      },
      "source": [
        "train_data[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.82755375,  0.810429  ,  0.810429  , ...,  0.5878072 ,\n",
              "          0.6563062 ,  0.70768046],\n",
              "        [ 0.810429  ,  0.79330426,  0.79330426, ...,  0.5535577 ,\n",
              "          0.60493195,  0.63918144],\n",
              "        [ 0.79330426,  0.79330426,  0.79330426, ...,  0.45080918,\n",
              "          0.5193082 ,  0.57068247],\n",
              "        ...,\n",
              "        [ 0.34806067,  0.38231018,  0.38231018, ...,  0.09118938,\n",
              "          0.12543888,  0.15968838],\n",
              "        [ 0.3651854 ,  0.3651854 ,  0.3651854 , ...,  0.12543888,\n",
              "          0.14256364,  0.15968838],\n",
              "        [ 0.3651854 ,  0.34806067,  0.34806067, ...,  0.14256364,\n",
              "          0.14256364,  0.12543888]],\n",
              "\n",
              "       [[ 0.8004202 ,  0.78291327,  0.78291327, ...,  0.5378152 ,\n",
              "          0.57282925,  0.6078432 ],\n",
              "        [ 0.78291327,  0.76540625,  0.76540625, ...,  0.50280124,\n",
              "          0.5378152 ,  0.57282925],\n",
              "        [ 0.76540625,  0.76540625,  0.76540625, ...,  0.3977592 ,\n",
              "          0.4677872 ,  0.5203082 ],\n",
              "        ...,\n",
              "        [ 0.03011205,  0.04761905,  0.06512605, ...,  0.04761905,\n",
              "          0.08263306,  0.11764706],\n",
              "        [ 0.04761905,  0.04761905,  0.04761905, ...,  0.08263306,\n",
              "          0.10014006,  0.11764706],\n",
              "        [ 0.04761905,  0.03011205,  0.03011205, ...,  0.10014006,\n",
              "          0.10014006,  0.08263306]],\n",
              "\n",
              "       [[ 0.8622224 ,  0.8447932 ,  0.8447932 , ...,  0.68793046,\n",
              "          0.74021804,  0.77507645],\n",
              "        [ 0.8447932 ,  0.827364  ,  0.827364  , ...,  0.65307206,\n",
              "          0.70535964,  0.7227889 ],\n",
              "        [ 0.827364  ,  0.827364  ,  0.827364  , ...,  0.56592613,\n",
              "          0.6356429 ,  0.6705013 ],\n",
              "        ...,\n",
              "        [-0.13124175, -0.11381256, -0.09638336, ...,  0.13019615,\n",
              "          0.14762534,  0.18248373],\n",
              "        [-0.14867094, -0.14867094, -0.14867094, ...,  0.14762534,\n",
              "          0.16505454,  0.18248373],\n",
              "        [-0.16610013, -0.18352933, -0.18352933, ...,  0.16505454,\n",
              "          0.16505454,  0.14762534]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXnwqDrhmBvo"
      },
      "source": [
        "class Data(Dataset):\n",
        "  def __init__(self, datafile):\n",
        "    self.datafile = datafile\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.datafile.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.datafile[idx][0]\n",
        "    y = int(self.datafile[idx][1])\n",
        "    if y == 0:\n",
        "      lbl = torch.tensor([1.0,0.0])\n",
        "    if y == 1:\n",
        "      lbl = torch.tensor([0.0,1.0])\n",
        "\n",
        "    return img, lbl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6eiW-j8Hj_v"
      },
      "source": [
        "#train_data_class.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPM5hCY7pJ2I"
      },
      "source": [
        "# Make data class\n",
        "train_data_class = Data(train_data)\n",
        "val_data_class = Data(val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UGX7H6qpbNg"
      },
      "source": [
        "# Make data loader\n",
        "train_loader = DataLoader(train_data_class, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data_class, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t91dTOt-pyVG"
      },
      "source": [
        "dataloaders = {'train': train_loader, 'val': val_loader}\n",
        "dataset_sizes = {'train': train_data.shape[0], 'val': val_data.shape[0]}\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88lGfLJTq_nM"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ImxHRBWq-O_"
      },
      "source": [
        "## Model as feature extractor\n",
        "model_conv = models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Sequential(nn.Linear(num_ftrs, 2), torch.nn.Sigmoid())\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as opposed to before.\n",
        "#optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_conv = optim.Adam(model_conv.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LwMPp94qH2Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8d891b3-5aac-44e8-8599-2f2cd90bbadc"
      },
      "source": [
        "# Testing with one batch\n",
        "\n",
        "img, lbl = next(iter(dataloaders['val']))\n",
        "\n",
        "outputs = model_conv(img)\n",
        "value, preds = torch.max(outputs, 1)\n",
        "loss = criterion(outputs, lbl)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0388, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1QGDlaGqVna"
      },
      "source": [
        "def train_model(model, optimizer,criterion, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = 1.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    value, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                \n",
        "                running_corrects += torch.sum(preds == torch.argmax(labels,1)) #labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Q4fo6PuJWW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1081a368-d942-453a-9a27-7ed5cde4e5f7"
      },
      "source": [
        "model_conv = train_model(model_conv,  optimizer_conv, criterion,  exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.0672 Acc: 0.9814\n",
            "val Loss: 0.0366 Acc: 1.0000\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.0366 Acc: 0.9912\n",
            "val Loss: 0.0247 Acc: 1.0000\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.0263 Acc: 0.9912\n",
            "val Loss: 0.0164 Acc: 1.0000\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.0207 Acc: 0.9967\n",
            "val Loss: 0.0110 Acc: 1.0000\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.0191 Acc: 0.9934\n",
            "val Loss: 0.0175 Acc: 1.0000\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.0182 Acc: 0.9923\n",
            "val Loss: 0.0056 Acc: 1.0000\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.0166 Acc: 0.9956\n",
            "val Loss: 0.0085 Acc: 1.0000\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.0134 Acc: 0.9989\n",
            "val Loss: 0.0065 Acc: 1.0000\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.0163 Acc: 0.9967\n",
            "val Loss: 0.0057 Acc: 1.0000\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.0128 Acc: 0.9978\n",
            "val Loss: 0.0078 Acc: 1.0000\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.0122 Acc: 0.9978\n",
            "val Loss: 0.0056 Acc: 1.0000\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.0144 Acc: 0.9978\n",
            "val Loss: 0.0061 Acc: 1.0000\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0141 Acc: 0.9967\n",
            "val Loss: 0.0063 Acc: 1.0000\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0105 Acc: 0.9989\n",
            "val Loss: 0.0052 Acc: 1.0000\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0161 Acc: 0.9934\n",
            "val Loss: 0.0058 Acc: 1.0000\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.0134 Acc: 0.9989\n",
            "val Loss: 0.0067 Acc: 1.0000\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.0111 Acc: 0.9989\n",
            "val Loss: 0.0060 Acc: 1.0000\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0112 Acc: 0.9978\n",
            "val Loss: 0.0050 Acc: 1.0000\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0139 Acc: 0.9967\n",
            "val Loss: 0.0054 Acc: 1.0000\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0137 Acc: 0.9978\n",
            "val Loss: 0.0055 Acc: 1.0000\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0125 Acc: 0.9978\n",
            "val Loss: 0.0052 Acc: 1.0000\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0136 Acc: 0.9967\n",
            "val Loss: 0.0061 Acc: 1.0000\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0103 Acc: 0.9989\n",
            "val Loss: 0.0062 Acc: 1.0000\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0109 Acc: 1.0000\n",
            "val Loss: 0.0055 Acc: 1.0000\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0099 Acc: 1.0000\n",
            "val Loss: 0.0051 Acc: 1.0000\n",
            "\n",
            "Training complete in 36m 51s\n",
            "Best val Acc: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw8aVGvZB1D-"
      },
      "source": [
        "torch.save(model_conv.state_dict(), '/content/drive/My Drive/dataset/model-resnet18-2.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}